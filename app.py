# app.py
import os
import time
import pandas as pd
import streamlit as st
import docx
from PyPDF2 import PdfReader

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

from prompt import PROMPT_FTE  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå prompt.py ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏® PROMPT_FTE

# =========================
# üîß ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å & ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ + Avatar
# =========================
AVATAR_PATH = "assets/green-bot.png"   # <<-- ‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡∏ö‡∏≠‡∏ó‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
PAGE_ICON = AVATAR_PATH if os.path.exists(AVATAR_PATH) else "üü¢"

st.set_page_config(page_title="FTE Chatbot ‚Ä¢ KMUTNB", page_icon=PAGE_ICON, layout="centered")
st.title("üí¨ Welcome to Faculty of Technical Education, KMUTNB")

# =========================
# üîê API KEY & Model config
# =========================
api_key = st.secrets.get("GEMINI_APIKEY")
if not api_key:
    st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_APIKEY ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .streamlit/secrets.toml ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤.")
    st.stop()

genai.configure(api_key=api_key)

generation_config = {
    "temperature": 0.1,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 1024,
    "response_mime_type": "text/plain",
}
SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}
MODEL_NAME = "gemini-2.0-flash"

model = genai.GenerativeModel(
    model_name=MODEL_NAME,
    safety_settings=SAFETY_SETTINGS,
    generation_config=generation_config,
    system_instruction=PROMPT_FTE,
)

# =========================
# üìÅ Utilities: Load files (cached)
# =========================
@st.cache_data(show_spinner=False)
def extract_text_from_docx(docx_path: str) -> str:
    try:
        d = docx.Document(docx_path)
        return "\n".join([p.text for p in d.paragraphs if p.text.strip()])
    except Exception as e:
        return f"[WARN] ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Word ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}"

@st.cache_data(show_spinner=False)
def extract_text_from_pdf(pdf_path: str) -> str:
    try:
        reader = PdfReader(pdf_path)
        parts = []
        for page in reader.pages:
            t = page.extract_text() or ""
            if t.strip():
                parts.append(t)
        return "\n".join(parts)
    except Exception as e:
        return f"[WARN] ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå PDF ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}"

@st.cache_data(show_spinner=False)
def load_excel_as_text(excel_path: str, max_rows: int = 80) -> str:
    try:
        df = pd.read_excel(excel_path)
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå/‡πÅ‡∏ñ‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î payload
        if df.shape[1] > 8:
            df = df.iloc[:, :8]
        if len(df) > max_rows:
            df = df.head(max_rows)
        return df.to_csv(index=False)
    except Exception as e:
        return f"[WARN] ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}"

@st.cache_data(show_spinner=False)
def build_reference_corpus(
    excel_file="FTE-DATASET.xlsx",
    word_file="Data Set chatbotfte.docx",
    pdf_file="Data Set chatbotfte.pdf",
    max_chars=45_000,
) -> str:
    parts = []
    if os.path.exists(excel_file):
        parts.append("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel (CSV):\n" + load_excel_as_text(excel_file))
    if os.path.exists(word_file):
        parts.append("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Word:\n" + extract_text_from_docx(word_file))
    if os.path.exists(pdf_file):
        parts.append("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå PDF:\n" + extract_text_from_pdf(pdf_file))

    blob = "\n\n".join(parts).strip()
    if len(blob) > max_chars:
        blob = blob[:max_chars] + "\n\n[TRUNCATED]"
    return blob

REFERENCE_BLOB = build_reference_corpus()

# =========================
# üß† Session State
# =========================
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "‡∏ó‡πà‡∏≤‡∏ô‡∏™‡∏ô‡πÉ‡∏à‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ì‡∏∞‡∏Ñ‡∏£‡∏∏‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏° ‡∏°‡∏à‡∏û. ‡∏î‡πâ‡∏≤‡∏ô‡πÉ‡∏î‡∏Ñ‡∏∞"}
    ]
if "previous_messages" not in st.session_state:
    st.session_state.previous_messages = []

# =========================
# üßπ Sidebar (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)
# =========================
with st.sidebar:
    st.header("‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏ó")
    col1, col2 = st.columns(2)
    if col1.button("üßπ Clear"):
        st.session_state.previous_messages = st.session_state.messages.copy()
        st.session_state.messages = [{"role": "assistant", "content": "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡πÄ‡∏ä‡∏ó‡∏Ç‡∏≠‡∏á‡∏ó‡πà‡∏≤‡∏ô"}]
        st.toast("‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏•‡πâ‡∏ß", icon="üßπ")
        st.rerun()
    if col2.button("üîÑ Restore"):
        if st.session_state.previous_messages:
            st.session_state.messages = st.session_state.previous_messages.copy()
            st.toast("‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏∑‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÅ‡∏•‡πâ‡∏ß", icon="üîÑ")
        else:
            st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏∑‡∏ô‡πÑ‡∏î‡πâ")

# =========================
# üó£Ô∏è Render History (assistant avatar = green bot icon if available)
# =========================
assistant_avatar = AVATAR_PATH if os.path.exists(AVATAR_PATH) else "üü¢"

for msg in st.session_state.messages:
    if msg["role"] == "assistant":
        st.chat_message("assistant", avatar=assistant_avatar).write(msg["content"])
    else:
        st.chat_message(msg["role"]).write(msg["content"])

# =========================
# üß© History builder for Gemini
# =========================
def build_history_for_gemini(messages):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà Gemini ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à
    - ‡∏î‡∏±‡∏ô‡∏Ñ‡∏≠‡∏£‡πå‡∏õ‡∏±‡∏™‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô context ‡πÅ‡∏£‡∏Å (‡∏ù‡∏±‡πà‡∏á user)
    - ‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
    """
    history = []
    if REFERENCE_BLOB:
        history.append({"role": "user", "parts": [{"text": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:\n" + REFERENCE_BLOB}]})
    for m in messages:
        role = "user" if m["role"] == "user" else "model"
        history.append({"role": role, "parts": [{"text": m["content"]}]})
    return history

# =========================
# üöÄ Typing-effect streaming
# =========================
def stream_typing_response(chat_session, prompt_text: str, typing_delay: float = 0.004) -> str:
    """
    ‡∏™‡∏ï‡∏£‡∏µ‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å Gemini ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ö‡∏ö '‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå'
    - ‡πÑ‡∏°‡πà‡∏°‡∏µ dropdown/expander
    - ‡πÇ‡∏ä‡∏ß‡πå '‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‚Ä¶' ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏¥‡∏î
    - ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏à‡∏ô‡∏à‡∏ö
    """
    status = st.empty()         # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß (‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡∏¥‡∏î)
    placeholder = st.empty()    # ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≠‡∏¢ ‡πÜ ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
    status.write("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‚Ä¶")

    full_text = ""
    first_char_written = False
    try:
        for chunk in chat_session.send_message(prompt_text, stream=True):
            text = getattr(chunk, "text", "") or ""
            for ch in text:
                if not first_char_written:
                    status.empty()           # ‡∏•‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏¥‡∏°‡∏û‡πå
                    first_char_written = True
                full_text += ch
                placeholder.markdown(full_text)  # ‡πÉ‡∏ä‡πâ markdown ‡πÉ‡∏´‡πâ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡∏™‡∏ß‡∏¢
                time.sleep(typing_delay)
        status.empty()
    except Exception as e:
        status.empty()
        placeholder.markdown(f"> [‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢] ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏ï‡∏£‡∏µ‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: `{e}`")
    return full_text

# =========================
# üí¨ Chat input & response
# =========================
prompt = st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...")
if prompt:
    # ‡∏ù‡∏±‡πà‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ + ‡∏™‡∏£‡πâ‡∏≤‡∏á chat session
    history_payload = build_history_for_gemini(st.session_state.messages[:-1])  # ‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° prompt ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ã‡πâ‡∏≥
    chat_session = model.start_chat(history=history_payload)

    # ‡∏ù‡∏±‡πà‡∏á‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ ‚Äî ‡πÉ‡∏ä‡πâ‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡∏ö‡∏≠‡∏ó‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    with st.chat_message("assistant", avatar=assistant_avatar):
        normalized = prompt.strip().lower()

        if normalized == "history":
            history_text = "\n".join(
                [f"{m['role'].capitalize()}: {m['content']}" for m in st.session_state.messages]
            )
            # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏™‡∏ß‡∏¢ ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏™‡∏î‡∏á‡∏î‡πâ‡∏ß‡∏¢ typing effect
            tmp_session = genai.GenerativeModel(
                model_name=MODEL_NAME,
                safety_settings=SAFETY_SETTINGS,
                generation_config=generation_config,
                system_instruction=PROMPT_FTE,
            ).start_chat(history=[])
            reply = stream_typing_response(
                chat_session=tmp_session,
                prompt_text=f"‡∏™‡∏£‡∏∏‡∏õ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á:\n\n{history_text}",
                typing_delay=0.003
            )

        elif normalized.startswith("add") or normalized.endswith("add"):
            # ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏î‡πâ‡∏ß‡∏¢ typing effect ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô
            text = "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ñ‡πà‡∏∞"
            ph = st.empty()
            reply = ""
            for ch in text:
                reply += ch
                ph.markdown(reply)
                time.sleep(0.004)

        else:
            # ‡∏ï‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å: stream + typing effect
            reply = stream_typing_response(chat_session, prompt_text=prompt, typing_delay=0.004)

    # ‡πÄ‡∏Å‡πá‡∏ö‡∏•‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ (assistant)
    st.session_state.messages.append({"role": "assistant", "content": reply})
