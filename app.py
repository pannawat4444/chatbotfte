import os
import google.generativeai as genai
import pandas as pd
import streamlit as st
from prompt import PROMPT_FTE # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå prompt.py ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# üîê ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡∏à‡∏≤‡∏Å st.secrets
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏µ‡∏¢‡πå 'GEMINI_APIKEY' ‡πÉ‡∏ô st.secrets ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
if "GEMINI_APIKEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_APIKEY"])
else:
    st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_APIKEY ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .streamlit/secrets.toml ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤.")
    st.stop() # ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÅ‡∏≠‡∏õ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ API Key

# ‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Model
generation_config = {
    "temperature": 0.1,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 1024,
    "response_mime_type": "text/plain",
}

# üîê ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

# üîç ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Gemini
model = genai.GenerativeModel(
    model_name="gemini-2.0-flash",
    safety_settings=SAFETY_SETTINGS,
    generation_config=generation_config,
    system_instruction=PROMPT_FTE,
)

# üîÅ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏ä‡∏ó
def clear_history():
    st.session_state["messages"] = [
        {"role": "model", "content": "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡πÄ‡∏ä‡∏ó‡∏Ç‡∏≠‡∏á‡∏ó‡πà‡∏≤‡∏ô"}
    ]
    st.rerun()

# üîß Sidebar: ‡∏õ‡∏∏‡πà‡∏° Clear ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
with st.sidebar:
    if st.button("üßπ Clear History"):
        clear_history()

# üßæ ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏≠‡∏õ‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤
st.title("üí¨ Welcome to Faculty of Technical Education, KMUTNB")

# üîÉ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô session state ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "model",
            "content": "‡∏ó‡πà‡∏≤‡∏ô‡∏™‡∏ô‡πÉ‡∏à‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ì‡∏∞‡∏Ñ‡∏£‡∏∏‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏° ‡∏°‡∏à‡∏û. ‡∏î‡πâ‡∏≤‡∏ô‡πÉ‡∏î‡∏Ñ‡∏∞",
        }
    ]

# üìÇ ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel
# *** ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏ä‡πâ Relative Path (‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á) ‡πÅ‡∏ó‡∏ô Absolute Path ***
# ‡πÑ‡∏ü‡∏•‡πå FTE-DATASET.xlsx ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö app.py ‡πÉ‡∏ô GitHub repository
file_path = "FTE-DATASET.xlsx" 
try:
    df = pd.read_excel(file_path)
    file_content = df.to_string(index=False)
except Exception as e:
    st.error(f"Error reading file: {e}. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå Excel 'FTE-DATASET.xlsx' ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô GitHub repository ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö app.py ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà.")
    st.stop()

# üí¨ ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°
for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

# üí° ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ prompt ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤
if prompt := st.chat_input():
    st.session_state["messages"].append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    def generate_response():
        if prompt.strip().lower() == "history":
            history_text = "\n".join(
                [f"{msg['role'].capitalize()}: {msg['content']}" for msg in st.session_state["messages"]]
            )
            st.chat_message("model").write(f"üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤:\n\n{history_text}")
            st.session_state["messages"].append({"role": "model", "content": f"üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤:\n\n{history_text}"})
        elif prompt.lower().startswith("add") or prompt.lower().endswith("add"):
            st.chat_message("model").write("‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ñ‡πà‡∏∞")
            st.session_state["messages"].append({"role": "model", "content": "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ñ‡πà‡∏∞"})
        else:
            history = [
                {"role": msg["role"], "parts": [{"text": msg["content"]}]}
                for msg in st.session_state["messages"]
            ]
            # ‡πÅ‡∏ó‡∏£‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Excel ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
            history.insert(0, {"role": "user", "parts": [{"text": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel:\n" + file_content}]})
            
            chat_session = model.start_chat(history=history)
            response = chat_session.send_message(prompt)
            st.session_state["messages"].append({"role": "model", "content": response.text})
            st.chat_message("model").write(response.text)

    generate_response()
